{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca4c92d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TfidfVectorizer(max_df=0.8, max_features=1000, min_df=5, ngram_range=(1, 2)),\n",
       " CalibratedClassifierCV(estimator=LinearSVC(class_weight='balanced',\n",
       "                                            random_state=271828)),\n",
       " {'xgboost': '3.1.2', 'sklearn': '1.8.0', 'numpy': '2.3.5'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "vectorizer = load(\"../models/lai_ms_tfidf_vectorizer.joblib\")\n",
    "model, metadata = load(\"../models/lai_ms_model_classifier.joblib\")\n",
    "\n",
    "vectorizer, model, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88a0ae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNZ: 2\n",
      "Shape: (1, 1000)\n"
     ]
    }
   ],
   "source": [
    "X_new = vectorizer.transform([\"Gostaria acessar dados ministério\"])\n",
    "print(\"NNZ:\", X_new.nnz)\n",
    "print(\"Shape:\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ade8801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pt-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pt_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9d64e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apoia',\n",
       " 'vinte',\n",
       " 'oito',\n",
       " 'põe',\n",
       " 'tempo',\n",
       " 'como',\n",
       " 'próxima',\n",
       " 'comprida',\n",
       " 'cedo',\n",
       " 'talvez']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('pt_core_news_sm')\n",
    "stopwords_spacy = nlp.Defaults.stop_words\n",
    "list(stopwords_spacy)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100748b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/isaaclourenco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aos',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords_nltk = stopwords.words('portuguese')\n",
    "list(stopwords_nltk)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df6eb98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "both_stopwords = set(stopwords_nltk) | set(stopwords_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2460344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_stop_word(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    tokens = text.split()\n",
    "\n",
    "    tokens = filter(lambda token: token not in both_stopwords, tokens)\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b975406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_lemmatizer(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    txt = [token.lemma_ for token in doc]\n",
    "\n",
    "    txt = [word for word in txt if len(word) > 2]\n",
    "\n",
    "    return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24dd7aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predict(text, vectorizer, model):\n",
    "    texts = pd.Series([text])\n",
    "    no_stop_word_texts = texts.str.lower().apply(remove_stop_word)\n",
    "    lemmatized_texts = no_stop_word_texts.str.lower().apply(spacy_lemmatizer)\n",
    "    X_new = vectorizer.transform(lemmatized_texts)\n",
    "    return X_new.nnz, model.predict_proba(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fb4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "lais_outros = [\n",
    "    \"Eu tenho direito de acessar meus dados armazenados no sistema da justiça.\",\n",
    "    \"Processo de número 500 me dá direito de acessar os dados gerados.\",\n",
    "    \"Tenho meus direitos. Quero que vocês me enviem um relatório contendo os últimos processos judiciais no meu nome.\",\n",
    "    \"solicitar acessar dados justiça\",\n",
    "    \"solicitar acessar dados ministério justiça\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe87ffaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gostaria de solicitar meu prontuário médico, por gentiliza.\n",
      "NNZ: 4\n",
      "Outro: 0.5541690036284468\n",
      "MS: 0.4458309963715532\n",
      "\n",
      "Eu tenho direito de acessar meus dados armazenados no sistema da justiça.\n",
      "NNZ: 4\n",
      "Outro: 0.9981231350720311\n",
      "MS: 0.0018768649279689333\n",
      "\n",
      "Processo de número 500 me dá direito de acessar os dados gerados.\n",
      "NNZ: 5\n",
      "Outro: 0.9707633890474436\n",
      "MS: 0.029236610952556353\n",
      "\n",
      "Tenho meus direitos. Quero que vocês me enviem um relatório contendo os últimos processos judiciais no meu nome.\n",
      "NNZ: 7\n",
      "Outro: 0.971775361865998\n",
      "MS: 0.028224638134001844\n",
      "\n",
      "solicitar acessar dados justiça\n",
      "NNZ: 4\n",
      "Outro: 0.9963477540930519\n",
      "MS: 0.003652245906948186\n",
      "\n",
      "solicitar acessar dados ministério justiça\n",
      "NNZ: 5\n",
      "Outro: 0.9894028625836405\n",
      "MS: 0.010597137416359325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lai in lais_outros:\n",
    "    print(lai)\n",
    "    nnz, pred_proba = predict(lai, vectorizer=vectorizer, model=model)\n",
    "    print(\"NNZ:\", nnz)\n",
    "    print(\"Outro:\", pred_proba[0][0])\n",
    "    print(\"MS:\", pred_proba[0][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c05de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lais_ms = [\n",
    "    \"Gostaria de solicitar meu prontuário médico, por gentiliza.\",\n",
    "    \"Quero o prontuário gerado pelo médico Alberto Carlos que estava em plantão no dia 14. Ele me atendeu.\",\n",
    "    \"Quero acesso aos medicamentos mais demandados pela polução no ano de 2024.\",\n",
    "    \"Quero um relatório contendo as vacinas mais aplicadas no ano de 2024 em Santa Cruz, Rio Grande do Norte.\",\n",
    "    \"Preciso de um relatório detalhado da frequências dos médicos em Unidades de Pronto Atendimento em Natal no último ano.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdf32684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gostaria de solicitar meu prontuário médico, por gentiliza.\n",
      "NNZ: 4\n",
      "Outro: 0.5541690036284468\n",
      "MS: 0.4458309963715532\n",
      "\n",
      "Quero o prontuário gerado pelo médico Alberto Carlos que estava em plantão no dia 14. Ele me atendeu.\n",
      "NNZ: 4\n",
      "Outro: 0.7676288566896332\n",
      "MS: 0.2323711433103668\n",
      "\n",
      "Quero acesso aos medicamentos mais demandados pela polução no ano de 2024.\n",
      "NNZ: 4\n",
      "Outro: 0.4624400085510606\n",
      "MS: 0.5375599914489394\n",
      "\n",
      "Quero um relatório contendo as vacinas mais aplicadas no ano de 2024 em Santa Cruz, Rio Grande do Norte.\n",
      "NNZ: 6\n",
      "Outro: 0.9576437417926027\n",
      "MS: 0.0423562582073974\n",
      "\n",
      "Preciso de um relatório detalhado da frequências dos médicos em Unidades de Pronto Atendimento em Natal no último ano.\n",
      "NNZ: 7\n",
      "Outro: 0.6111677831105864\n",
      "MS: 0.38883221688941366\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lai in lais_ms:\n",
    "    print(lai)\n",
    "    nnz, pred_proba = predict(lai, vectorizer=vectorizer, model=model)\n",
    "    print(\"NNZ:\", nnz)\n",
    "    print(\"Outro:\", pred_proba[0][0])\n",
    "    print(\"MS:\", pred_proba[0][1])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f9eb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NNZ: 3\n",
      "Outro: 0.9796624097788731\n",
      "MS: 0.02033759022112683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lai = input()\n",
    "nnz, pred_proba = predict(lai, vectorizer=vectorizer, model=model)\n",
    "print(\"NNZ:\", nnz)\n",
    "print(\"Outro:\", pred_proba[0][0])\n",
    "print(\"MS:\", pred_proba[0][1])\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
